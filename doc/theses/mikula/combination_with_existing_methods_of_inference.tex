\chapter{Combination with Existing Methods of Inference} \label{CHAPTER_combination_with_existings_methods_of_inference}
In this chapter, we describe how to incorporate the inferred statements to existing methods of XML schema inference. We focus on a class of methods which are based on a creation and subsequent simplification of the initial grammar (as discussed in Chapter \ref{chapter_analysis_of_recent_approaches}).

The initial grammar contains rules of form $e \rightarrow e_1e_2\dots e_k$, where $e$ is an element and $e_1, \dots , e_k$ are its subelements. After the simplification, the simplified grammar contain rules of form $e \rightarrow E$, where $E$ is a regular expression composed of subelements of element $e$, describing its content.

Attributes of elements are not contained in the grammar directly, but every element carries an information on its attributes.

The combination with such methods of inference is straightforward. The rules of the grammar describe the XML structure using the most general aspect of elements and their subelements. Since the statements inferred by our method do not involve the XML structure by defining a subelement structure of elements, there are no conflicts between the grammar rules and our statements that need to be resolved.

Our statements are of the three following forms. The first one is $P \rightarrow T$, where $P$ is a PathType representing an XQuery path selecting a set of elements or attributes, and $T$ is an XSD built-in atomic type.

The second and third forms are $K = (C,P,\{L\})$ and $K_f = (C(P_1,\{L_1\}) \rightarrow (P_2,\{L_2\}))$, representing a key and a foreign key.

In all three cases, we want to determine elements from the grammar (or their attributes), targeted by the respective paths ($P$ from the first form and $C$ from the second and third form). This is done in two steps. The first one is normalization of a particular PathType and the second one is selection of the targeted elements.

\section{Evaluation of Paths}
A path represented by PathType can contain variable references and association of these references with other paths. That is the reason why the normalization is convenient. It simply finds the variable references in the path and replaces them with steps from the associated paths, which are normalized recursively.

The selection of elements is a simplified XPath evaluation. The simplification involves two aspects; the evaluation is not performed upon XML data, but the simplified grammar containing rules with a regular expression on their right side, and, partially related, predicates in path steps are not evaluated, they are ignored.

It iterates through steps of a path, maintaining a so-called \emph{context set}, which is a set of elements to evaluate the current step upon. The evaluation of one step is shown in Algorithm \ref{FUNC_evaluate_step}. For the retaining of readability of the code, we present an evaluation of self or descendant, child, and attribute axes, and nodes specified by name.

\begin{algorithm}
\caption{Function evaluateStep}
\label{FUNC_evaluate_step}
\begin{algorithmic}[1]
\REQUIRE{\ \\
	$step$: An instance of StepExprNode representing a step of the path to evaluate.
	$contextSet$: A set of elements and attributes to evaluate $step$ upon.
	$grammar$: The grammar.
}

\ENSURE A context set after the step evaluation.

\IF{$is(step,$ SelfOrDescendantStep$)$}
	\RETURN $evaluateStep\_selfOrDescendant(contextSet, grammar)$
\ENDIF

\STATE $newContextSet :=$ an empty set

\STATE $axisKind := step.getChild(axisNode).axisKind$
\STATE $nodeName := step.getChild(axisNode).getChild(nameTestNode).name$
\IF{$axisKind =$ CHILD}
	\FORALL{$node \in contextSet$}
		\IF{$node$ is element}
			\STATE $subelements := getTokens(grammar[node])$
			\FORALL{$subelement \in subelements$}
				\IF{$subelement.name = nodeName$}
					\STATE add $subelement$ to $newContextSet$
				\ENDIF
			\ENDFOR
		\ENDIF
	\ENDFOR
\ELSIF{$axisKind =$ ATTRIBUTE}
	\FORALL{$node \in contextSet$}
		\IF{$node$ is element}
			\STATE $attributes := node.attributes$
			\FORALL{$attribute \in attributes$}
				\IF{$attribute.name = nodeName$}
					\STATE add $attribute$ to $newContextSet$
				\ENDIF
			\ENDFOR
		\ENDIF
	\ENDFOR
\ENDIF

\RETURN $newContextSet$
\end{algorithmic}
\end{algorithm}

At first, the algorithm determines the axis of the step. If it is self or descendant axis, it returns the result of \texttt{evaluateStep\_selfOrDescendant} function. This function returns the given context set extended by all descendants of the elements from the context set in the given grammar.

If the axis is child axis, for each element in the context set, the algorithm determines its subelement using the grammar, and, if those with the name equal to the name specified by to step are added to the resulting context set. Function \texttt{getTokens} at line 10 retrieves all elements from a regular expression. A specific form of the regular expression is not important, because we only need to know which elements are possible subelements of the particular element.

And, at last, if the axis is attribute axis, elements from the context set are searched to contain an attribute with the specified name and those found attributes are added to the result.

\section{Saving the Inferred Statements}
In case of keys, the algorithm iterates through the inferred key statements. A key's context path $C$ is evaluated and the key is assigned to the target elements selected by the context path, one element can be assigned with multiple keys. Additionally, each key is assigned with a list of foreign keys that are referencing it.

In case of inferred types, the situation is slightly less simple, because there can occur conflicting statements. The examples of such conflicts for path $P$ without predicates are $P_1 \rightarrow$ \texttt{date}, $P_2 \rightarrow$ \texttt{string}, and, $P_1 \rightarrow$ \texttt{byte}, $P_2 \rightarrow$ \texttt{int}, where $P_1$, $P_2$ are paths that when stripped of predicates, they equal $P$.

Note that, in both examples, one type is castable to the other (\texttt{date} to \texttt{string}, and \texttt{byte} to \texttt{int}). Both types are inferred correctly for nodes targeted by $P$, but one of them was inferred from a more convenient expression and is more precise.

Consider these two expressions; PathType $P$ is compared to an integral literal constant, and, PathType $P$ is an argument of a function where a formal type of the argument is \texttt{byte}. The first expression is utilized to infer statement $P \rightarrow$ \texttt{integer}, and the second one to infer statement $P \rightarrow$ \texttt{byte}. Both of the types are correct, but the second one is more accurate.

A problem emerges for example if PathType $P$ is compared to an integral constant, and the real type of elements (or attributes) selected by $P$ is \texttt{double}. In that case, statement $P \rightarrow$ \texttt{integer} is inferred, but it is not correct.

\subsection{Verification using XML data}
To solve the problems, we propose a simple verification using XML data.

For each normalized PathType $P$ from the inferred type statements $\mathcal{S}_t$, we find set $\mathcal{T}_P$ of all inferred types. $\mathcal{T}_P = \{T|(P \rightarrow T) \in \mathcal{S}_t\}$. Then, we create sequence $\mathcal{T}_P'$ by ordering the set $\mathcal{T}_P$ from the most specific type to the most general one. For example, if $\mathcal{T}_P = \{$\texttt{double}, \texttt{byte}, \texttt{int}$\}$, $\mathcal{T}_P' = ($\texttt{byte}, \texttt{int}, \texttt{double}$)$.

Since we have the XML data and path $P$ is an XQuery path, we can use an XQuery processor (a program that evaluates XQuery paths or queries) to select nodes $N$ targeted by $P$. The verification algorithm iterates through $\mathcal{T}_P'$ and for each $T' \in \mathcal{T}_P'$ it checks if every node in $N$ conforms to $T'$. If so, $T'$ is the inferred type for nodes $N$ (and PathType $P$), else the inferred type is \texttt{string}.
