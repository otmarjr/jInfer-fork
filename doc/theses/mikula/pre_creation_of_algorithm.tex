\chapter{Pre-creation of Algorithm} \label{CHAPTER_precreation_of_algorithm}
According to the analysis in the previous chapter, there is quite a wide range of possible utilizations of XQuery queries. Besides analysis of what information can be extracted from queries, it is needed to devise how the queries will be processed. This chapter discusses some questions and issues that emerged in an early phase of the algorithm fabrication.

\section{Input Data}
The first important question is what is the input of the algorithm. A basic query utilization can be achieved by analysis of queries without any other input data. The analysis of XQuery in the previous chapter discusses mostly XQuery constructs which can be utilized without respective XML data, for example the inference of built-in types. This independence is also the main advantage of this approach, if there are no XML data available, this approach can be still used. 

A more complex method can utilize queries along with the respective XML data. As discussed in the previous chapter, an element and attribute structure can be inferred from the XML data in a more convenient way. Also, the XML data can be used to verify information inferred from the queries or vice-versa. For example, utilizing the queries, some attribute is considered a key of its element. But in the data there are elements with the same value of this attribute, and thus, it cannot be the key. Vice-versa, we have a notion that the attribute might be the key but we are not sure about that. Analysing of the data and finding that values of the attribute are unique can increase our confidence. 

Another step can be evaluation of the queries using the XML data and consecutive analysis of the results. And even the process of evaluation itself can be analysed to obtain some useful information. For instance, these are partial results of evaluating of expressions (elements selected by each path expression, real arguments in function calls, etc).

\section{Forms of Query Precessing}
Another important question is how the queries can be processed. Will they be just searched for certain patterns like it is performed in method \cite{Necasky:2009:DXK:1529282.1529414} or will they be processed in a more sophisticated way? That can mean incorporating lexical and syntax analyses, known from creation of compilers, or even a form of an analysis of semantics \cite{compilers}.

The result of lexical and syntax analyses can be a kind of so-called syntax tree \cite{compilers}. It is a structure representing a word according to a formal grammar of a language. In our case, the language is XQuery, its grammar is defined in \cite{w3c_xquery} and every query is a word of the XQuery language. Leaves of the tree represent terminals of the grammar while inner nodes represent non-terminals. From the point of view of this work, the syntax tree can be perceived as a preprocessed form of a query keeping its complete meaning and making its further processing more convenient. For instance, the tree can simplify a search for FLWOR statements. It is transitioned and nodes representing FLWORs are found. Then each subtree determined by one of the found nodes represents a FLWOR statement and it can be analysed further.

The syntax tree can be also extended by additional information. An example is a static analysis of expression types. Types of literal expressions are defined, functions have return types, path expressions can return nodes, etc. Types of complex expressions can be determined applying the rules defined in \cite{w3c_xquery}. The inferred expression types can be helpful for example in the analysis of built-in types of nodes as discussed in the previous chapter. 

The following text is an example of inference of a more complex query processing. Consider the following part of a query.
\begin{verbatim}
declare function local:getB($id as xs:string) as element() {
  //A[@id = $id]/B
}
... local:getBs("id") > 10 ...
\end{verbatim}
The query consists of a function declaration and an arithmetic comparison. The comparison compares the result of the function call and literal value \texttt{10}. For the type of \texttt{10} is \texttt{xs:integer} the type of the function call has to be convertible to \texttt{xs:double}. Thus, it has to be a numeric type. The function returns a path expression typed as \texttt{element()}. That means the function returns one element. In the path expression, the argument \texttt{\$id} can be substituted by the real value specified in the call. Thus, the return expression is \texttt{//A[@id = "id"]/B}. Therefore, we can infer that element \texttt{B} in element \texttt{A} with attribute \texttt{id} equalling string value \texttt{"id"} is of some numeric type. And, since the function is parametrized, there is a notion that this statement may be correct also for other elements \texttt{A} and \texttt{B}.

While simpler approaches of the query processing such as the pattern finding limit possibilities of the query utilization, a more complex processing of queries provides a better starting point for consecutive analyses and also for further refinements and additions. Therefore, we decided to incorporate query processing using the lexical and syntax analyses.

\section{Inference of XML Structure}
The question of inference of XML structure from queries is partially discussed in the previous chapter. We are able to infer XML structure from queries without their evaluation, but in a limited way. This inference is based on an analysis of path expressions. Its limitation involves the following issues. When we infer some subelements of a certain element we often cannot be sure about their number of occurrences. Also, we cannot be sure if every occurrence of a certain element contains the subelements and we even do not know if at least one occurrence of the element contains them. Thus, the inferred statement is more likely an indication than a fact about the structure.

Since the inference of XML structure utilizing only queries is not clear, we need the XML data, if we want to infer the structure more precisely. And, if we have the XML data, we can infer the structure directly from them using an existing approach and utilize queries to refine its result.

\section{Extension of an Existing Approach}
The existing approaches of XML schema inference deal mainly with inference of XML structure. Hence, the extension of an existing approach will be a kind of an independent addition instead of modification and refinement of its core algorithm.

The existing approaches take the XML data on their input. Therefore, the basic idea is that the input will be extended also for XQuery queries and the algorithm will consist of three phases. The first phase will be taken from an existing approach and it will process the XML data to infer the XML structure. The second phase will process the XQuery queries and it will infer statements that can be inferred independently of the XML data. The third phase will merge the statements inferred in the second phase into the resulting schema. This phase may also infer additional statements from both the XML data and the queries or it may try to verify the statements from the second phase with respect to the XML data.

A more advanced method can exploit queries to refine a core algorithm (e.g. merging of PTA) of an existing approach. The approach described in \cite{Vosta:2008:EAC:1802514.1802522} distinguishes elements with the same name, but a different content model and context. Some information from queries may help to improve this algorithm. For example, consider an XML representation of company data containing names of employees, costumers, and products represented by element \texttt{name}. The names of employees and costumers consists of two subelements for first name and surname. The names of products are atomic strings. During analysis of available queries, we may find that elements representing the names of employees and elements representing the names of costumers are processed in the same way (e.g. they are mixed in one sequence), while elements representing the names of products are processed separately. This suggests that the elements representing the names of employees and costumers have the same semantic and the same content model which is different from the content model of the elements representing the names of products.